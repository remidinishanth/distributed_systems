Refer:
* https://www.youtube.com/watch?v=SZorAJ4I-sA&ab_channel=GoogleCloudTech

  - 🚀 Transformers revolutionize machine learning, enabling tasks like translation and code generation.
  - 🔍 BERT, GPT-3, and T5 are all transformer-based models reshaping natural language processing.
  - 🧠 Positional encodings help capture word order, improving language understanding.
  - ⚡ Transformers allow parallel processing, making them faster to train than RNNs.
  - 📊 Self-attention enables context-aware understanding, enhancing meaning recognition in language.
  - 🌐 BERT utilizes semi-supervised learning for better performance on unlabeled data.

* Attention is all you need https://arxiv.org/abs/1706.03762
* https://www.youtube.com/watch?v=Pnd8bCJ4Z3A
