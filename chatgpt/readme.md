Refer:
* https://www.youtube.com/watch?v=SZorAJ4I-sA&ab_channel=GoogleCloudTech

  - ğŸš€ Transformers revolutionize machine learning, enabling tasks like translation and code generation.
  - ğŸ” BERT, GPT-3, and T5 are all transformer-based models reshaping natural language processing.
  - ğŸ§  Positional encodings help capture word order, improving language understanding.
  - âš¡ Transformers allow parallel processing, making them faster to train than RNNs.
  - ğŸ“Š Self-attention enables context-aware understanding, enhancing meaning recognition in language.
  - ğŸŒ BERT utilizes semi-supervised learning for better performance on unlabeled data.

* Attention is all you need https://arxiv.org/abs/1706.03762
* https://www.youtube.com/watch?v=Pnd8bCJ4Z3A
